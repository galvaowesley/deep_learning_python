{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "funcoes_ativacao.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Up7zvHnVfRdd",
        "colab_type": "text"
      },
      "source": [
        "Importações iniciais\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFgRQ9BDfYJt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPnpUvO9f-49",
        "colab_type": "text"
      },
      "source": [
        "Step Function\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VARgt2lhtdGa",
        "colab_type": "text"
      },
      "source": [
        "A Step Function funciona como um classifidor binário, onde se estabelece um valor X como limite e caso Y(como saida da rede neural) seja maior ou menor que X, a o neurônio da rede será ativado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKc1o9WDgC6p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def stepFunction(soma):\n",
        "  if(soma >= 1):\n",
        "    return 1\n",
        "  else:\n",
        "    return 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioWZNWZfhIsP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "teste = stepFunction(-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSJVf2OAhNEE",
        "colab_type": "code",
        "outputId": "3360d0f1-129b-4b9b-b518-a9fdd596cbd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "teste"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_EV6yWlhdBT",
        "colab_type": "text"
      },
      "source": [
        "Sigmoid Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGj6WFb6u733",
        "colab_type": "text"
      },
      "source": [
        "A função Sigmoide funciona como não linear, o que pode significar que ela não traça uma reta entre os valores, mas um S.Podendo assim, causar especificidade na rede neural. Os valores podem variar entre 0 e 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnKhJ9PrhgPN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoidFunction(soma):\n",
        "  return 1 / (1 + np.exp(-soma))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztn7sWxMh849",
        "colab_type": "code",
        "outputId": "d8b7459e-9e14-40ef-aede-d6e3dddc06eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "teste = sigmoidFunction(2.1)\n",
        "teste"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8909031788043871"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAUqUOkJjBS3",
        "colab_type": "text"
      },
      "source": [
        "Hyperbolic tanget"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhf3UvLkvzvU",
        "colab_type": "text"
      },
      "source": [
        "A função tangente não é linear, tendo certa semelhança com a função sigmóide. Onde, seus valores podem varia de -1 e 1, o que apresenta vantagem em relação ao sinal dos valores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvSA9OFBjF4e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tahnFunction(soma):\n",
        "  return (np.exp(soma) - np.exp(-soma)) / (np.exp(soma) + np.exp(-soma))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iC0BGrA2jZF4",
        "colab_type": "code",
        "outputId": "c890ea1e-7d53-4b6a-ce9d-e1a888f3082f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "teste = tahnFunction(2.1)\n",
        "teste"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9704519366134541"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ce-h3a3IlBet",
        "colab_type": "text"
      },
      "source": [
        "ReLU(rectified linear units)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ue3Fu1cgwsLd",
        "colab_type": "text"
      },
      "source": [
        "ReLU é a função de ativação mais amplamente utilizada em redes neurais atualmente.A função ReLU é não linear, o que significa que podemos facilmente copiar os erros para trás e ter várias camadas de neurônios ativados pela função ReLU. Os valores podem variar entre a própria entrada e 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISciczMzlHgs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reluFunction(soma):\n",
        "  if soma >= 0:\n",
        "    return soma\n",
        "  else:\n",
        "    return 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AhGhR3FlSW_",
        "colab_type": "code",
        "outputId": "e0ac418b-5117-4d81-b975-9f4d72073092",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "teste = reluFunction(2.1)\n",
        "teste"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGverFItlhp7",
        "colab_type": "text"
      },
      "source": [
        "Linear Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvSALwNQxaTS",
        "colab_type": "text"
      },
      "source": [
        "A função Linear funciona basicamente como um espelho das suas entradas, as devolvendo. A mesma é muito utilizada em problemas de regressão."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0D3xcW5ljCg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def linearFunction(soma):\n",
        "  return soma"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZ1Bzbpnltqa",
        "colab_type": "code",
        "outputId": "dbe01e12-4660-4e4a-9f26-d491419a399d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "teste = linearFunction(2.1)\n",
        "teste"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yqzqpEOl8uu",
        "colab_type": "text"
      },
      "source": [
        "Softmax Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-8Z1KR5yyQk",
        "colab_type": "text"
      },
      "source": [
        "A função Softmax é muito utilizada em problemas de classificação, podendo trabalhar com apenas duas classes.Onde os valores podem estar entre 0 e 1, podendo gerar probabilidades das suas entradas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pNTHxn4mIKF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def softmaxFunction(x):\n",
        "  ex = np.exp(x)\n",
        "  return ex / ex.sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bra-av-rmlXF",
        "colab_type": "code",
        "outputId": "2c4dc3eb-64e4-47b0-bb29-e2ba549c4a02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "valores = [5.0,2.0,1.3]\n",
        "print(softmaxFunction(valores))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.93065625 0.04633465 0.0230091 ]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}